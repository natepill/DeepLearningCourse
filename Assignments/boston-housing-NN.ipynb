{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Plan\n",
    "* Clean/Preprocess data\n",
    "* Build NN with all features (13 input nodes)\n",
    "* ReLU activation for hidden layers and Linear transformation activation for output layer\n",
    "* Evaluate model and try to improve accuracy based on:\n",
    "    * Different activations for hidden layer\n",
    "    * Differnt number of hidden layers and nodes in hidden layers\n",
    "    * Change input data to remove irrelevant columns based on CorrPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston # Boston Housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Boston Housing DF\n",
    "\n",
    "boston = load_boston()\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.head()\n",
    "bos.columns = boston.feature_names\n",
    "# bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bos # Input values\n",
    "y = boston.target # true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bos.columns) # number of input nodes in input layer\n",
    "# bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Sequential ANN for classification\n",
    "classifier = Sequential()\n",
    "\n",
    "# hidden units = (13 + 1) /  =7\n",
    "\n",
    "#Input layer\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=13, units=7, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding second hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding output layer\n",
    "classifier.add(Dense(activation=\"linear\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "* Trying compiling the ANN with sgd instead of adam\n",
    "* Different batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our ANN with Adam GD, Mean Squared Error error metric, and we are optimizing for accuracy\n",
    "classifier.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 593.7540 - mean_squared_error: 593.7540\n",
      "Epoch 2/100\n",
      "379/379 [==============================] - 0s 229us/step - loss: 572.5232 - mean_squared_error: 572.5232\n",
      "Epoch 3/100\n",
      "379/379 [==============================] - 0s 241us/step - loss: 494.0974 - mean_squared_error: 494.0974\n",
      "Epoch 4/100\n",
      "379/379 [==============================] - 0s 254us/step - loss: 344.8282 - mean_squared_error: 344.8282\n",
      "Epoch 5/100\n",
      "379/379 [==============================] - 0s 237us/step - loss: 179.5151 - mean_squared_error: 179.5151\n",
      "Epoch 6/100\n",
      "379/379 [==============================] - 0s 218us/step - loss: 82.0339 - mean_squared_error: 82.0339\n",
      "Epoch 7/100\n",
      "379/379 [==============================] - 0s 213us/step - loss: 51.3995 - mean_squared_error: 51.3995\n",
      "Epoch 8/100\n",
      "379/379 [==============================] - 0s 247us/step - loss: 40.2319 - mean_squared_error: 40.2319\n",
      "Epoch 9/100\n",
      "379/379 [==============================] - 0s 243us/step - loss: 34.1311 - mean_squared_error: 34.1311\n",
      "Epoch 10/100\n",
      "379/379 [==============================] - 0s 216us/step - loss: 30.5411 - mean_squared_error: 30.5411\n",
      "Epoch 11/100\n",
      "379/379 [==============================] - 0s 246us/step - loss: 28.4250 - mean_squared_error: 28.4250\n",
      "Epoch 12/100\n",
      "379/379 [==============================] - 0s 234us/step - loss: 26.8650 - mean_squared_error: 26.8650\n",
      "Epoch 13/100\n",
      "379/379 [==============================] - 0s 256us/step - loss: 25.7518 - mean_squared_error: 25.7518\n",
      "Epoch 14/100\n",
      "379/379 [==============================] - 0s 248us/step - loss: 24.9510 - mean_squared_error: 24.9510\n",
      "Epoch 15/100\n",
      "379/379 [==============================] - 0s 228us/step - loss: 24.2775 - mean_squared_error: 24.2775\n",
      "Epoch 16/100\n",
      "379/379 [==============================] - 0s 234us/step - loss: 23.7416 - mean_squared_error: 23.7416\n",
      "Epoch 17/100\n",
      "379/379 [==============================] - 0s 211us/step - loss: 23.2565 - mean_squared_error: 23.2565\n",
      "Epoch 18/100\n",
      "379/379 [==============================] - 0s 245us/step - loss: 22.9236 - mean_squared_error: 22.9236\n",
      "Epoch 19/100\n",
      "379/379 [==============================] - 0s 206us/step - loss: 22.4214 - mean_squared_error: 22.4214\n",
      "Epoch 20/100\n",
      "379/379 [==============================] - 0s 251us/step - loss: 22.0011 - mean_squared_error: 22.0011\n",
      "Epoch 21/100\n",
      "379/379 [==============================] - 0s 220us/step - loss: 21.6780 - mean_squared_error: 21.6780\n",
      "Epoch 22/100\n",
      "379/379 [==============================] - 0s 223us/step - loss: 21.3312 - mean_squared_error: 21.3312\n",
      "Epoch 23/100\n",
      "379/379 [==============================] - 0s 215us/step - loss: 20.9424 - mean_squared_error: 20.9424\n",
      "Epoch 24/100\n",
      "379/379 [==============================] - 0s 227us/step - loss: 20.6813 - mean_squared_error: 20.6813\n",
      "Epoch 25/100\n",
      "379/379 [==============================] - 0s 220us/step - loss: 20.4130 - mean_squared_error: 20.4130\n",
      "Epoch 26/100\n",
      "379/379 [==============================] - 0s 230us/step - loss: 20.2226 - mean_squared_error: 20.2226\n",
      "Epoch 27/100\n",
      "379/379 [==============================] - 0s 220us/step - loss: 19.9233 - mean_squared_error: 19.9233\n",
      "Epoch 28/100\n",
      "379/379 [==============================] - 0s 212us/step - loss: 19.6184 - mean_squared_error: 19.6184\n",
      "Epoch 29/100\n",
      "379/379 [==============================] - 0s 257us/step - loss: 19.4238 - mean_squared_error: 19.4238\n",
      "Epoch 30/100\n",
      "379/379 [==============================] - 0s 331us/step - loss: 19.2455 - mean_squared_error: 19.2455\n",
      "Epoch 31/100\n",
      "379/379 [==============================] - 0s 408us/step - loss: 18.9101 - mean_squared_error: 18.9101\n",
      "Epoch 32/100\n",
      "379/379 [==============================] - 0s 248us/step - loss: 18.7766 - mean_squared_error: 18.7766\n",
      "Epoch 33/100\n",
      "379/379 [==============================] - 0s 244us/step - loss: 18.5774 - mean_squared_error: 18.5774\n",
      "Epoch 34/100\n",
      "379/379 [==============================] - 0s 260us/step - loss: 18.3633 - mean_squared_error: 18.3633\n",
      "Epoch 35/100\n",
      "379/379 [==============================] - 0s 266us/step - loss: 18.2392 - mean_squared_error: 18.2392\n",
      "Epoch 36/100\n",
      "379/379 [==============================] - 0s 249us/step - loss: 17.8827 - mean_squared_error: 17.8827\n",
      "Epoch 37/100\n",
      "379/379 [==============================] - 0s 253us/step - loss: 17.7845 - mean_squared_error: 17.7845\n",
      "Epoch 38/100\n",
      "379/379 [==============================] - 0s 256us/step - loss: 17.5754 - mean_squared_error: 17.5754\n",
      "Epoch 39/100\n",
      "379/379 [==============================] - 0s 255us/step - loss: 17.3697 - mean_squared_error: 17.3697\n",
      "Epoch 40/100\n",
      "379/379 [==============================] - 0s 283us/step - loss: 17.1353 - mean_squared_error: 17.1353\n",
      "Epoch 41/100\n",
      "379/379 [==============================] - 0s 299us/step - loss: 16.9488 - mean_squared_error: 16.9488\n",
      "Epoch 42/100\n",
      "379/379 [==============================] - 0s 304us/step - loss: 16.8062 - mean_squared_error: 16.8062\n",
      "Epoch 43/100\n",
      "379/379 [==============================] - 0s 257us/step - loss: 16.6109 - mean_squared_error: 16.6109\n",
      "Epoch 44/100\n",
      "379/379 [==============================] - 0s 225us/step - loss: 16.4217 - mean_squared_error: 16.4217\n",
      "Epoch 45/100\n",
      "379/379 [==============================] - 0s 238us/step - loss: 16.2788 - mean_squared_error: 16.2788\n",
      "Epoch 46/100\n",
      "379/379 [==============================] - 0s 238us/step - loss: 16.1084 - mean_squared_error: 16.1084\n",
      "Epoch 47/100\n",
      "379/379 [==============================] - 0s 213us/step - loss: 15.8985 - mean_squared_error: 15.8985\n",
      "Epoch 48/100\n",
      "379/379 [==============================] - 0s 221us/step - loss: 15.7020 - mean_squared_error: 15.7020\n",
      "Epoch 49/100\n",
      "379/379 [==============================] - 0s 283us/step - loss: 15.4755 - mean_squared_error: 15.4755\n",
      "Epoch 50/100\n",
      "379/379 [==============================] - 0s 425us/step - loss: 15.2059 - mean_squared_error: 15.2059\n",
      "Epoch 51/100\n",
      "379/379 [==============================] - 0s 339us/step - loss: 15.0082 - mean_squared_error: 15.0082\n",
      "Epoch 52/100\n",
      "379/379 [==============================] - 0s 262us/step - loss: 14.8681 - mean_squared_error: 14.8681\n",
      "Epoch 53/100\n",
      "379/379 [==============================] - 0s 238us/step - loss: 14.5799 - mean_squared_error: 14.5799\n",
      "Epoch 54/100\n",
      "379/379 [==============================] - 0s 313us/step - loss: 14.3697 - mean_squared_error: 14.3697\n",
      "Epoch 55/100\n",
      "379/379 [==============================] - 0s 261us/step - loss: 14.0726 - mean_squared_error: 14.0726\n",
      "Epoch 56/100\n",
      "379/379 [==============================] - 0s 295us/step - loss: 13.9800 - mean_squared_error: 13.9800\n",
      "Epoch 57/100\n",
      "379/379 [==============================] - 0s 312us/step - loss: 13.8004 - mean_squared_error: 13.8004\n",
      "Epoch 58/100\n",
      "379/379 [==============================] - 0s 298us/step - loss: 13.5099 - mean_squared_error: 13.5099\n",
      "Epoch 59/100\n",
      "379/379 [==============================] - 0s 364us/step - loss: 13.2613 - mean_squared_error: 13.2613\n",
      "Epoch 60/100\n",
      "379/379 [==============================] - 0s 303us/step - loss: 13.0914 - mean_squared_error: 13.0914\n",
      "Epoch 61/100\n",
      "379/379 [==============================] - 0s 263us/step - loss: 13.0331 - mean_squared_error: 13.0331\n",
      "Epoch 62/100\n",
      "379/379 [==============================] - 0s 300us/step - loss: 12.8773 - mean_squared_error: 12.8773\n",
      "Epoch 63/100\n",
      "379/379 [==============================] - 0s 308us/step - loss: 12.5957 - mean_squared_error: 12.5957\n",
      "Epoch 64/100\n",
      "379/379 [==============================] - 0s 309us/step - loss: 12.5826 - mean_squared_error: 12.5826\n",
      "Epoch 65/100\n",
      "379/379 [==============================] - 0s 291us/step - loss: 12.4267 - mean_squared_error: 12.4267\n",
      "Epoch 66/100\n",
      "379/379 [==============================] - 0s 297us/step - loss: 12.2115 - mean_squared_error: 12.2115\n",
      "Epoch 67/100\n",
      "379/379 [==============================] - 0s 327us/step - loss: 12.1944 - mean_squared_error: 12.1944\n",
      "Epoch 68/100\n",
      "379/379 [==============================] - 0s 306us/step - loss: 12.0339 - mean_squared_error: 12.0339\n",
      "Epoch 69/100\n",
      "379/379 [==============================] - 0s 324us/step - loss: 11.8903 - mean_squared_error: 11.8903\n",
      "Epoch 70/100\n",
      "379/379 [==============================] - 0s 250us/step - loss: 11.8558 - mean_squared_error: 11.8558\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 497us/step - loss: 11.6764 - mean_squared_error: 11.6764\n",
      "Epoch 72/100\n",
      "379/379 [==============================] - 0s 297us/step - loss: 11.5948 - mean_squared_error: 11.5948\n",
      "Epoch 73/100\n",
      "379/379 [==============================] - 0s 293us/step - loss: 11.5405 - mean_squared_error: 11.5405\n",
      "Epoch 74/100\n",
      "379/379 [==============================] - 0s 282us/step - loss: 11.4425 - mean_squared_error: 11.4425\n",
      "Epoch 75/100\n",
      "379/379 [==============================] - 0s 294us/step - loss: 11.3819 - mean_squared_error: 11.3819\n",
      "Epoch 76/100\n",
      "379/379 [==============================] - 0s 253us/step - loss: 11.3413 - mean_squared_error: 11.3413\n",
      "Epoch 77/100\n",
      "379/379 [==============================] - 0s 225us/step - loss: 11.1935 - mean_squared_error: 11.1935\n",
      "Epoch 78/100\n",
      "379/379 [==============================] - 0s 221us/step - loss: 11.2234 - mean_squared_error: 11.2234\n",
      "Epoch 79/100\n",
      "379/379 [==============================] - 0s 305us/step - loss: 11.0918 - mean_squared_error: 11.0918\n",
      "Epoch 80/100\n",
      "379/379 [==============================] - 0s 311us/step - loss: 11.0064 - mean_squared_error: 11.0064\n",
      "Epoch 81/100\n",
      "379/379 [==============================] - 0s 284us/step - loss: 10.9193 - mean_squared_error: 10.9193\n",
      "Epoch 82/100\n",
      "379/379 [==============================] - 0s 250us/step - loss: 10.8289 - mean_squared_error: 10.8289\n",
      "Epoch 83/100\n",
      "379/379 [==============================] - 0s 244us/step - loss: 10.7727 - mean_squared_error: 10.7727\n",
      "Epoch 84/100\n",
      "379/379 [==============================] - 0s 215us/step - loss: 10.7166 - mean_squared_error: 10.7166\n",
      "Epoch 85/100\n",
      "379/379 [==============================] - 0s 331us/step - loss: 10.7116 - mean_squared_error: 10.7116\n",
      "Epoch 86/100\n",
      "379/379 [==============================] - 0s 227us/step - loss: 10.6288 - mean_squared_error: 10.6288\n",
      "Epoch 87/100\n",
      "379/379 [==============================] - 0s 244us/step - loss: 10.4995 - mean_squared_error: 10.4995\n",
      "Epoch 88/100\n",
      "379/379 [==============================] - 0s 247us/step - loss: 10.5460 - mean_squared_error: 10.5460\n",
      "Epoch 89/100\n",
      "379/379 [==============================] - 0s 224us/step - loss: 10.4287 - mean_squared_error: 10.4287\n",
      "Epoch 90/100\n",
      "379/379 [==============================] - 0s 254us/step - loss: 10.4308 - mean_squared_error: 10.4308\n",
      "Epoch 91/100\n",
      "379/379 [==============================] - 0s 268us/step - loss: 10.3104 - mean_squared_error: 10.3104\n",
      "Epoch 92/100\n",
      "379/379 [==============================] - 0s 289us/step - loss: 10.3179 - mean_squared_error: 10.3179\n",
      "Epoch 93/100\n",
      "379/379 [==============================] - 0s 262us/step - loss: 10.3270 - mean_squared_error: 10.3270\n",
      "Epoch 94/100\n",
      "379/379 [==============================] - 0s 272us/step - loss: 10.2810 - mean_squared_error: 10.2810\n",
      "Epoch 95/100\n",
      "379/379 [==============================] - 0s 282us/step - loss: 10.1553 - mean_squared_error: 10.1553\n",
      "Epoch 96/100\n",
      "379/379 [==============================] - 0s 266us/step - loss: 10.0946 - mean_squared_error: 10.0946\n",
      "Epoch 97/100\n",
      "379/379 [==============================] - 0s 264us/step - loss: 10.1153 - mean_squared_error: 10.1153\n",
      "Epoch 98/100\n",
      "379/379 [==============================] - 0s 261us/step - loss: 10.0468 - mean_squared_error: 10.0468\n",
      "Epoch 99/100\n",
      "379/379 [==============================] - 0s 258us/step - loss: 9.9905 - mean_squared_error: 9.9905\n",
      "Epoch 100/100\n",
      "379/379 [==============================] - 0s 242us/step - loss: 9.9240 - mean_squared_error: 9.9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d11e0f0>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reminder: batch size is a hyperparameter that defines the number of samples to work \n",
    "# through before updating the internal model parameters\n",
    "# For the difference between epochs and batchsize, read: https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "\n",
    "# Using Mini batch GD\n",
    "# Fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size = 5, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7526961007468101"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Regression model\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare it to sklearn's linear regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
