{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Plan\n",
    "* Clean/Preprocess data\n",
    "* Build NN with all features (13 input nodes)\n",
    "* ReLU activation for hidden layers and Linear transformation activation for output layer\n",
    "* Evaluate model and try to improve accuracy based on:\n",
    "    * Different activations for hidden layer\n",
    "    * Differnt number of hidden layers and nodes in hidden layers\n",
    "    * Change input data to remove irrelevant columns based on CorrPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston # Boston Housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Boston Housing DF\n",
    "\n",
    "boston = load_boston()\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.head()\n",
    "bos.columns = boston.feature_names\n",
    "# bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bos # Input values\n",
    "y = boston.target # true values\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bos.columns) # number of input nodes in input layer\n",
    "# bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train = sc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Sequential ANN for classification\n",
    "classifier = Sequential()\n",
    "\n",
    "# hidden units = (13 + 1) /  =7\n",
    "\n",
    "#Input layer\n",
    "classifier.add(Dense(activation=\"linear\", input_dim=13, units=1, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding second hidden layer\n",
    "# classifier.add(Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding output layer\n",
    "# classifier.add(Dense(activation=\"linear\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "* Trying compiling the ANN with sgd instead of adam\n",
    "* Different batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our ANN with Adam GD, Mean Squared Error error metric, and we are optimizing for accuracy\n",
    "classifier.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "379/379 [==============================] - 0s 814us/step - loss: 19.8274 - mean_squared_error: 19.8274\n",
      "Epoch 2/100\n",
      "379/379 [==============================] - 0s 779us/step - loss: 19.8371 - mean_squared_error: 19.8371\n",
      "Epoch 3/100\n",
      "379/379 [==============================] - 0s 833us/step - loss: 19.8352 - mean_squared_error: 19.8352\n",
      "Epoch 4/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.8245 - mean_squared_error: 19.8245\n",
      "Epoch 5/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.8326 - mean_squared_error: 19.8326\n",
      "Epoch 6/100\n",
      "379/379 [==============================] - 0s 816us/step - loss: 19.8296 - mean_squared_error: 19.8296\n",
      "Epoch 7/100\n",
      "379/379 [==============================] - 0s 684us/step - loss: 19.8316 - mean_squared_error: 19.8316\n",
      "Epoch 8/100\n",
      "379/379 [==============================] - 0s 727us/step - loss: 19.8388 - mean_squared_error: 19.8388\n",
      "Epoch 9/100\n",
      "379/379 [==============================] - 0s 753us/step - loss: 19.8246 - mean_squared_error: 19.8246\n",
      "Epoch 10/100\n",
      "379/379 [==============================] - 0s 787us/step - loss: 19.8326 - mean_squared_error: 19.8326\n",
      "Epoch 11/100\n",
      "379/379 [==============================] - 0s 676us/step - loss: 19.8223 - mean_squared_error: 19.8223\n",
      "Epoch 12/100\n",
      "379/379 [==============================] - 0s 800us/step - loss: 19.8111 - mean_squared_error: 19.8111\n",
      "Epoch 13/100\n",
      "379/379 [==============================] - 0s 752us/step - loss: 19.8189 - mean_squared_error: 19.8189\n",
      "Epoch 14/100\n",
      "379/379 [==============================] - 0s 720us/step - loss: 19.8163 - mean_squared_error: 19.8163\n",
      "Epoch 15/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.8190 - mean_squared_error: 19.8190\n",
      "Epoch 16/100\n",
      "379/379 [==============================] - 0s 653us/step - loss: 19.8149 - mean_squared_error: 19.8149\n",
      "Epoch 17/100\n",
      "379/379 [==============================] - 0s 837us/step - loss: 19.8072 - mean_squared_error: 19.8072\n",
      "Epoch 18/100\n",
      "379/379 [==============================] - 0s 966us/step - loss: 19.8172 - mean_squared_error: 19.8172\n",
      "Epoch 19/100\n",
      "379/379 [==============================] - 0s 709us/step - loss: 19.8141 - mean_squared_error: 19.8141\n",
      "Epoch 20/100\n",
      "379/379 [==============================] - 0s 702us/step - loss: 19.8119 - mean_squared_error: 19.8119\n",
      "Epoch 21/100\n",
      "379/379 [==============================] - 0s 824us/step - loss: 19.8177 - mean_squared_error: 19.8177\n",
      "Epoch 22/100\n",
      "379/379 [==============================] - 0s 982us/step - loss: 19.8094 - mean_squared_error: 19.8094\n",
      "Epoch 23/100\n",
      "379/379 [==============================] - 0s 887us/step - loss: 19.8030 - mean_squared_error: 19.8030\n",
      "Epoch 24/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.8012 - mean_squared_error: 19.8012\n",
      "Epoch 25/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.8115 - mean_squared_error: 19.8115\n",
      "Epoch 26/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.7966 - mean_squared_error: 19.7966\n",
      "Epoch 27/100\n",
      "379/379 [==============================] - 0s 939us/step - loss: 19.8063 - mean_squared_error: 19.8063\n",
      "Epoch 28/100\n",
      "379/379 [==============================] - 0s 785us/step - loss: 19.7975 - mean_squared_error: 19.7975\n",
      "Epoch 29/100\n",
      "379/379 [==============================] - 0s 687us/step - loss: 19.7952 - mean_squared_error: 19.7952\n",
      "Epoch 30/100\n",
      "379/379 [==============================] - 0s 642us/step - loss: 19.7964 - mean_squared_error: 19.7964\n",
      "Epoch 31/100\n",
      "379/379 [==============================] - 0s 745us/step - loss: 19.7990 - mean_squared_error: 19.7990\n",
      "Epoch 32/100\n",
      "379/379 [==============================] - 0s 667us/step - loss: 19.7885 - mean_squared_error: 19.7885\n",
      "Epoch 33/100\n",
      "379/379 [==============================] - 0s 637us/step - loss: 19.7996 - mean_squared_error: 19.7996\n",
      "Epoch 34/100\n",
      "379/379 [==============================] - 0s 799us/step - loss: 19.7934 - mean_squared_error: 19.7934\n",
      "Epoch 35/100\n",
      "379/379 [==============================] - 0s 654us/step - loss: 19.7967 - mean_squared_error: 19.7967\n",
      "Epoch 36/100\n",
      "379/379 [==============================] - 0s 656us/step - loss: 19.7830 - mean_squared_error: 19.7830\n",
      "Epoch 37/100\n",
      "379/379 [==============================] - 0s 748us/step - loss: 19.7885 - mean_squared_error: 19.7885\n",
      "Epoch 38/100\n",
      "379/379 [==============================] - 0s 779us/step - loss: 19.7980 - mean_squared_error: 19.7980\n",
      "Epoch 39/100\n",
      "379/379 [==============================] - 0s 786us/step - loss: 19.7898 - mean_squared_error: 19.7898\n",
      "Epoch 40/100\n",
      "379/379 [==============================] - 0s 615us/step - loss: 19.7870 - mean_squared_error: 19.7870\n",
      "Epoch 41/100\n",
      "379/379 [==============================] - 0s 643us/step - loss: 19.7839 - mean_squared_error: 19.7839\n",
      "Epoch 42/100\n",
      "379/379 [==============================] - 0s 628us/step - loss: 19.7847 - mean_squared_error: 19.7847\n",
      "Epoch 43/100\n",
      "379/379 [==============================] - 0s 617us/step - loss: 19.7933 - mean_squared_error: 19.7933\n",
      "Epoch 44/100\n",
      "379/379 [==============================] - 0s 758us/step - loss: 19.7909 - mean_squared_error: 19.7909\n",
      "Epoch 45/100\n",
      "379/379 [==============================] - 0s 966us/step - loss: 19.7849 - mean_squared_error: 19.78490s - loss: 21.2770 - mean_squared_error:\n",
      "Epoch 46/100\n",
      "379/379 [==============================] - 0s 789us/step - loss: 19.7825 - mean_squared_error: 19.7825\n",
      "Epoch 47/100\n",
      "379/379 [==============================] - 0s 764us/step - loss: 19.7801 - mean_squared_error: 19.7801\n",
      "Epoch 48/100\n",
      "379/379 [==============================] - 0s 645us/step - loss: 19.7754 - mean_squared_error: 19.7754\n",
      "Epoch 49/100\n",
      "379/379 [==============================] - 0s 751us/step - loss: 19.7754 - mean_squared_error: 19.7754\n",
      "Epoch 50/100\n",
      "379/379 [==============================] - 0s 789us/step - loss: 19.7794 - mean_squared_error: 19.7794\n",
      "Epoch 51/100\n",
      "379/379 [==============================] - 0s 874us/step - loss: 19.7861 - mean_squared_error: 19.7861\n",
      "Epoch 52/100\n",
      "379/379 [==============================] - 0s 659us/step - loss: 19.7777 - mean_squared_error: 19.7777\n",
      "Epoch 53/100\n",
      "379/379 [==============================] - 0s 676us/step - loss: 19.7801 - mean_squared_error: 19.78010s - loss: 21.3154 - mean_squared_erro\n",
      "Epoch 54/100\n",
      "379/379 [==============================] - 0s 712us/step - loss: 19.7871 - mean_squared_error: 19.7871\n",
      "Epoch 55/100\n",
      "379/379 [==============================] - 0s 783us/step - loss: 19.7887 - mean_squared_error: 19.7887\n",
      "Epoch 56/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.7837 - mean_squared_error: 19.7837\n",
      "Epoch 57/100\n",
      "379/379 [==============================] - 0s 685us/step - loss: 19.7770 - mean_squared_error: 19.7770\n",
      "Epoch 58/100\n",
      "379/379 [==============================] - 0s 757us/step - loss: 19.7748 - mean_squared_error: 19.7748\n",
      "Epoch 59/100\n",
      "379/379 [==============================] - 0s 685us/step - loss: 19.7681 - mean_squared_error: 19.7681\n",
      "Epoch 60/100\n",
      "379/379 [==============================] - 0s 901us/step - loss: 19.7706 - mean_squared_error: 19.7706\n",
      "Epoch 61/100\n",
      "379/379 [==============================] - ETA: 0s - loss: 16.5589 - mean_squared_error: 16.55 - 0s 795us/step - loss: 19.7891 - mean_squared_error: 19.7891\n",
      "Epoch 62/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.7708 - mean_squared_error: 19.7708: 0s - loss: 22.6130 - mean_squared_\n",
      "Epoch 63/100\n",
      "379/379 [==============================] - 0s 738us/step - loss: 19.7923 - mean_squared_error: 19.7923\n",
      "Epoch 64/100\n",
      "379/379 [==============================] - 0s 765us/step - loss: 19.7760 - mean_squared_error: 19.7760\n",
      "Epoch 65/100\n",
      "379/379 [==============================] - 0s 984us/step - loss: 19.7680 - mean_squared_error: 19.7680\n",
      "Epoch 66/100\n",
      "379/379 [==============================] - 0s 791us/step - loss: 19.7620 - mean_squared_error: 19.7620\n",
      "Epoch 67/100\n",
      "379/379 [==============================] - 0s 772us/step - loss: 19.7733 - mean_squared_error: 19.7733\n",
      "Epoch 68/100\n",
      "379/379 [==============================] - 0s 902us/step - loss: 19.7731 - mean_squared_error: 19.7731\n",
      "Epoch 69/100\n",
      "379/379 [==============================] - 0s 881us/step - loss: 19.7794 - mean_squared_error: 19.7794\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 857us/step - loss: 19.7662 - mean_squared_error: 19.76620s - loss: 18.7948 - mean_squared_error: 18.79\n",
      "Epoch 71/100\n",
      "379/379 [==============================] - 0s 806us/step - loss: 19.7799 - mean_squared_error: 19.7799\n",
      "Epoch 72/100\n",
      "379/379 [==============================] - 0s 683us/step - loss: 19.7715 - mean_squared_error: 19.7715\n",
      "Epoch 73/100\n",
      "379/379 [==============================] - 0s 817us/step - loss: 19.7649 - mean_squared_error: 19.7649\n",
      "Epoch 74/100\n",
      "379/379 [==============================] - 0s 755us/step - loss: 19.7540 - mean_squared_error: 19.7540\n",
      "Epoch 75/100\n",
      "379/379 [==============================] - 0s 739us/step - loss: 19.7592 - mean_squared_error: 19.7592\n",
      "Epoch 76/100\n",
      "379/379 [==============================] - 0s 755us/step - loss: 19.7655 - mean_squared_error: 19.7655\n",
      "Epoch 77/100\n",
      "379/379 [==============================] - 0s 821us/step - loss: 19.7671 - mean_squared_error: 19.7671\n",
      "Epoch 78/100\n",
      "379/379 [==============================] - 0s 710us/step - loss: 19.7643 - mean_squared_error: 19.7643\n",
      "Epoch 79/100\n",
      "379/379 [==============================] - 0s 674us/step - loss: 19.7537 - mean_squared_error: 19.7537\n",
      "Epoch 80/100\n",
      "379/379 [==============================] - 0s 757us/step - loss: 19.7647 - mean_squared_error: 19.7647\n",
      "Epoch 81/100\n",
      "379/379 [==============================] - 0s 902us/step - loss: 19.7647 - mean_squared_error: 19.7647\n",
      "Epoch 82/100\n",
      "379/379 [==============================] - 0s 867us/step - loss: 19.7564 - mean_squared_error: 19.7564\n",
      "Epoch 83/100\n",
      "379/379 [==============================] - 0s 914us/step - loss: 19.7687 - mean_squared_error: 19.7687\n",
      "Epoch 84/100\n",
      "379/379 [==============================] - 0s 702us/step - loss: 19.7618 - mean_squared_error: 19.7618\n",
      "Epoch 85/100\n",
      "379/379 [==============================] - 0s 979us/step - loss: 19.7640 - mean_squared_error: 19.76400s - loss: 19.4121 - mean_squared_error: 1\n",
      "Epoch 86/100\n",
      "379/379 [==============================] - 0s 879us/step - loss: 19.7680 - mean_squared_error: 19.7680\n",
      "Epoch 87/100\n",
      "379/379 [==============================] - 0s 775us/step - loss: 19.7658 - mean_squared_error: 19.7658\n",
      "Epoch 88/100\n",
      "379/379 [==============================] - 0s 844us/step - loss: 19.7632 - mean_squared_error: 19.7632\n",
      "Epoch 89/100\n",
      "379/379 [==============================] - 0s 851us/step - loss: 19.7618 - mean_squared_error: 19.7618\n",
      "Epoch 90/100\n",
      "379/379 [==============================] - 0s 694us/step - loss: 19.7535 - mean_squared_error: 19.7535\n",
      "Epoch 91/100\n",
      "379/379 [==============================] - 0s 874us/step - loss: 19.7449 - mean_squared_error: 19.7449\n",
      "Epoch 92/100\n",
      "379/379 [==============================] - 0s 790us/step - loss: 19.7477 - mean_squared_error: 19.7477\n",
      "Epoch 93/100\n",
      "379/379 [==============================] - 0s 865us/step - loss: 19.7556 - mean_squared_error: 19.7556\n",
      "Epoch 94/100\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 19.7587 - mean_squared_error: 19.7587: 0s - loss: 21.3570 - mean_squared_error: 21.35\n",
      "Epoch 95/100\n",
      "379/379 [==============================] - 0s 817us/step - loss: 19.7574 - mean_squared_error: 19.7574\n",
      "Epoch 96/100\n",
      "379/379 [==============================] - 0s 646us/step - loss: 19.7514 - mean_squared_error: 19.7514\n",
      "Epoch 97/100\n",
      "379/379 [==============================] - 0s 728us/step - loss: 19.7635 - mean_squared_error: 19.7635\n",
      "Epoch 98/100\n",
      "379/379 [==============================] - 0s 789us/step - loss: 19.7529 - mean_squared_error: 19.7529\n",
      "Epoch 99/100\n",
      "379/379 [==============================] - 0s 888us/step - loss: 19.7557 - mean_squared_error: 19.7557\n",
      "Epoch 100/100\n",
      "379/379 [==============================] - 0s 1000us/step - loss: 19.7461 - mean_squared_error: 19.7461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fddd240>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reminder: batch size is a hyperparameter that defines the number of samples to work \n",
    "# through before updating the internal model parameters\n",
    "# For the difference between epochs and batchsize, read: https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "\n",
    "# Using Mini batch GD\n",
    "# Fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size = 1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6302421219191374"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Regression model\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare our ANN to sklearn's linear regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202131"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_reg = LinearRegression().fit(X_train, y_train).score(X_test, y_test)\n",
    "linear_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
