{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Plan\n",
    "* Clean/Preprocess data\n",
    "* Build NN with all features (13 input nodes)\n",
    "* ReLU activation for hidden layers and Linear transformation activation for output layer\n",
    "* Evaluate model and try to improve accuracy based on:\n",
    "    * Different activations for hidden layer\n",
    "    * Differnt number of hidden layers and nodes in hidden layers\n",
    "    * Change input data to remove irrelevant columns based on CorrPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston # Boston Housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Boston Housing DF\n",
    "\n",
    "boston = load_boston()\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.head()\n",
    "bos.columns = boston.feature_names\n",
    "# bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bos # Input values\n",
    "y = boston.target # true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bos.columns) # number of input nodes in input layer\n",
    "# bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Sequential ANN for classification\n",
    "classifier = Sequential()\n",
    "\n",
    "# hidden units = (13 + 1) /  =7\n",
    "\n",
    "#Input layer\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=13, units=7, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding second hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding output layer\n",
    "classifier.add(Dense(activation=\"linear\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "* Trying compiling the ANN with sgd instead of adam\n",
    "* Different batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our ANN with Adam GD, Mean Squared Error error metric, and we are optimizing for accuracy\n",
    "classifier.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 10.5130 - mean_squared_error: 10.5130\n",
      "Epoch 2/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 10.4125 - mean_squared_error: 10.4125\n",
      "Epoch 3/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 10.1073 - mean_squared_error: 10.1073\n",
      "Epoch 4/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.9970 - mean_squared_error: 9.9970\n",
      "Epoch 5/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.8408 - mean_squared_error: 9.8408\n",
      "Epoch 6/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 9.7476 - mean_squared_error: 9.7476\n",
      "Epoch 7/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 9.6999 - mean_squared_error: 9.6999\n",
      "Epoch 8/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.6114 - mean_squared_error: 9.6114\n",
      "Epoch 9/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.6097 - mean_squared_error: 9.6097\n",
      "Epoch 10/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.4483 - mean_squared_error: 9.4483\n",
      "Epoch 11/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.4996 - mean_squared_error: 9.4996\n",
      "Epoch 12/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 9.3646 - mean_squared_error: 9.3646TA: 0s - loss: 8.8141 - mean_squar\n",
      "Epoch 13/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.3281 - mean_squared_error: 9.3281\n",
      "Epoch 14/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 9.5259 - mean_squared_error: 9.5259\n",
      "Epoch 15/200\n",
      "379/379 [==============================] - 0s 965us/step - loss: 9.3358 - mean_squared_error: 9.3358\n",
      "Epoch 16/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.3730 - mean_squared_error: 9.3730\n",
      "Epoch 17/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.1053 - mean_squared_error: 9.1053\n",
      "Epoch 18/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.2761 - mean_squared_error: 9.2761\n",
      "Epoch 19/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.1764 - mean_squared_error: 9.1764: 0s - loss: 9.0453 - mean_squared_error: 9.04\n",
      "Epoch 20/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 9.0774 - mean_squared_error: 9.0774\n",
      "Epoch 21/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.9633 - mean_squared_error: 8.9633\n",
      "Epoch 22/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.9939 - mean_squared_error: 8.9939\n",
      "Epoch 23/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.9579 - mean_squared_error: 8.9579\n",
      "Epoch 24/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.9016 - mean_squared_error: 8.9016\n",
      "Epoch 25/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.8062 - mean_squared_error: 8.8062\n",
      "Epoch 26/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.9048 - mean_squared_error: 8.9048\n",
      "Epoch 27/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.7405 - mean_squared_error: 8.7405\n",
      "Epoch 28/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.7123 - mean_squared_error: 8.7123\n",
      "Epoch 29/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.6447 - mean_squared_error: 8.6447\n",
      "Epoch 30/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.7457 - mean_squared_error: 8.7457\n",
      "Epoch 31/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.6748 - mean_squared_error: 8.6748\n",
      "Epoch 32/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.8335 - mean_squared_error: 8.8335\n",
      "Epoch 33/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.5109 - mean_squared_error: 8.5109\n",
      "Epoch 34/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.5334 - mean_squared_error: 8.5334\n",
      "Epoch 35/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.4844 - mean_squared_error: 8.4844\n",
      "Epoch 36/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.4041 - mean_squared_error: 8.4041\n",
      "Epoch 37/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.4059 - mean_squared_error: 8.4059\n",
      "Epoch 38/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.3436 - mean_squared_error: 8.3436\n",
      "Epoch 39/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.3947 - mean_squared_error: 8.3947\n",
      "Epoch 40/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.3637 - mean_squared_error: 8.3637\n",
      "Epoch 41/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.2802 - mean_squared_error: 8.2802\n",
      "Epoch 42/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.2782 - mean_squared_error: 8.2782\n",
      "Epoch 43/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 8.2519 - mean_squared_error: 8.2519\n",
      "Epoch 44/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.2338 - mean_squared_error: 8.2338\n",
      "Epoch 45/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.2327 - mean_squared_error: 8.2327\n",
      "Epoch 46/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.1971 - mean_squared_error: 8.1971\n",
      "Epoch 47/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.0025 - mean_squared_error: 8.0025\n",
      "Epoch 48/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.2488 - mean_squared_error: 8.2488\n",
      "Epoch 49/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.1389 - mean_squared_error: 8.1389\n",
      "Epoch 50/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.1290 - mean_squared_error: 8.1290\n",
      "Epoch 51/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.0000 - mean_squared_error: 8.0000\n",
      "Epoch 52/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.0889 - mean_squared_error: 8.0889\n",
      "Epoch 53/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.0702 - mean_squared_error: 8.0702\n",
      "Epoch 54/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 8.0013 - mean_squared_error: 8.0013\n",
      "Epoch 55/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.0073 - mean_squared_error: 8.0073: 0s - loss: 7.9366 - mean_squared_error: 7.\n",
      "Epoch 56/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.9797 - mean_squared_error: 7.9797\n",
      "Epoch 57/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.9950 - mean_squared_error: 7.9950\n",
      "Epoch 58/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.8966 - mean_squared_error: 7.8966\n",
      "Epoch 59/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.8966 - mean_squared_error: 7.8966\n",
      "Epoch 60/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.9221 - mean_squared_error: 7.9221\n",
      "Epoch 61/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 8.0440 - mean_squared_error: 8.0440\n",
      "Epoch 62/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.9181 - mean_squared_error: 7.9181\n",
      "Epoch 63/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.9302 - mean_squared_error: 7.9302: 0s - loss: 8.4604 - mean_squared_error\n",
      "Epoch 64/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.8067 - mean_squared_error: 7.8067: 0s - loss: 7.3988 - mean_squared_error: \n",
      "Epoch 65/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.9269 - mean_squared_error: 7.9269\n",
      "Epoch 66/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.8514 - mean_squared_error: 7.8514\n",
      "Epoch 67/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.7629 - mean_squared_error: 7.7629\n",
      "Epoch 68/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.7461 - mean_squared_error: 7.7461\n",
      "Epoch 69/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.8657 - mean_squared_error: 7.8657\n",
      "Epoch 70/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.8643 - mean_squared_error: 7.8643\n",
      "Epoch 71/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.7030 - mean_squared_error: 7.7030\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 1s 2ms/step - loss: 7.8148 - mean_squared_error: 7.8148\n",
      "Epoch 73/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.6336 - mean_squared_error: 7.6336\n",
      "Epoch 74/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.6863 - mean_squared_error: 7.6863: 0s - loss: 8.7775 - mean_squared_error: 8. - ETA: 0s - loss: 7.8308 - mean_squared_error: 7.\n",
      "Epoch 75/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.6644 - mean_squared_error: 7.6644\n",
      "Epoch 76/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.6562 - mean_squared_error: 7.6562\n",
      "Epoch 77/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.3784 - mean_squared_error: 7.3784\n",
      "Epoch 78/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.6459 - mean_squared_error: 7.6459\n",
      "Epoch 79/200\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 7.6155 - mean_squared_error: 7.6155\n",
      "Epoch 80/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.6167 - mean_squared_error: 7.6167\n",
      "Epoch 81/200\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7.6128 - mean_squared_error: 7.6128\n",
      "Epoch 82/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.6631 - mean_squared_error: 7.6631\n",
      "Epoch 83/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.5039 - mean_squared_error: 7.5039\n",
      "Epoch 84/200\n",
      "379/379 [==============================] - 0s 964us/step - loss: 7.5881 - mean_squared_error: 7.5881\n",
      "Epoch 85/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.6098 - mean_squared_error: 7.6098\n",
      "Epoch 86/200\n",
      "379/379 [==============================] - 0s 983us/step - loss: 7.5701 - mean_squared_error: 7.5701\n",
      "Epoch 87/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.5619 - mean_squared_error: 7.5619\n",
      "Epoch 88/200\n",
      "379/379 [==============================] - 0s 908us/step - loss: 7.4579 - mean_squared_error: 7.4579\n",
      "Epoch 89/200\n",
      "379/379 [==============================] - 0s 901us/step - loss: 7.4716 - mean_squared_error: 7.4716\n",
      "Epoch 90/200\n",
      "379/379 [==============================] - 0s 965us/step - loss: 7.5428 - mean_squared_error: 7.5428\n",
      "Epoch 91/200\n",
      "379/379 [==============================] - 0s 948us/step - loss: 7.5224 - mean_squared_error: 7.5224\n",
      "Epoch 92/200\n",
      "379/379 [==============================] - 0s 947us/step - loss: 7.3838 - mean_squared_error: 7.3838\n",
      "Epoch 93/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.5652 - mean_squared_error: 7.5652\n",
      "Epoch 94/200\n",
      "379/379 [==============================] - 0s 958us/step - loss: 7.3932 - mean_squared_error: 7.3932\n",
      "Epoch 95/200\n",
      "379/379 [==============================] - 0s 951us/step - loss: 7.5407 - mean_squared_error: 7.5407\n",
      "Epoch 96/200\n",
      "379/379 [==============================] - 0s 930us/step - loss: 7.4310 - mean_squared_error: 7.4310\n",
      "Epoch 97/200\n",
      "379/379 [==============================] - 0s 934us/step - loss: 7.4533 - mean_squared_error: 7.4533\n",
      "Epoch 98/200\n",
      "379/379 [==============================] - 0s 963us/step - loss: 7.3664 - mean_squared_error: 7.3664\n",
      "Epoch 99/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.3099 - mean_squared_error: 7.3099\n",
      "Epoch 100/200\n",
      "379/379 [==============================] - 0s 934us/step - loss: 7.4413 - mean_squared_error: 7.4413\n",
      "Epoch 101/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.3804 - mean_squared_error: 7.3804\n",
      "Epoch 102/200\n",
      "379/379 [==============================] - 0s 910us/step - loss: 7.4199 - mean_squared_error: 7.4199\n",
      "Epoch 103/200\n",
      "379/379 [==============================] - 0s 912us/step - loss: 7.3436 - mean_squared_error: 7.3436\n",
      "Epoch 104/200\n",
      "379/379 [==============================] - 0s 907us/step - loss: 7.4232 - mean_squared_error: 7.4232\n",
      "Epoch 105/200\n",
      "379/379 [==============================] - 0s 979us/step - loss: 7.2371 - mean_squared_error: 7.2371\n",
      "Epoch 106/200\n",
      "379/379 [==============================] - 0s 934us/step - loss: 7.3322 - mean_squared_error: 7.3322\n",
      "Epoch 107/200\n",
      "379/379 [==============================] - 0s 904us/step - loss: 7.4005 - mean_squared_error: 7.4005\n",
      "Epoch 108/200\n",
      "379/379 [==============================] - 0s 945us/step - loss: 7.3201 - mean_squared_error: 7.3201\n",
      "Epoch 109/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.3460 - mean_squared_error: 7.3460\n",
      "Epoch 110/200\n",
      "379/379 [==============================] - 0s 952us/step - loss: 7.2205 - mean_squared_error: 7.2205\n",
      "Epoch 111/200\n",
      "379/379 [==============================] - 0s 942us/step - loss: 7.2152 - mean_squared_error: 7.2152\n",
      "Epoch 112/200\n",
      "379/379 [==============================] - 0s 940us/step - loss: 7.3007 - mean_squared_error: 7.3007\n",
      "Epoch 113/200\n",
      "379/379 [==============================] - 0s 934us/step - loss: 7.2008 - mean_squared_error: 7.2008\n",
      "Epoch 114/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.2845 - mean_squared_error: 7.2845\n",
      "Epoch 115/200\n",
      "379/379 [==============================] - 0s 968us/step - loss: 7.2661 - mean_squared_error: 7.2661\n",
      "Epoch 116/200\n",
      "379/379 [==============================] - 0s 948us/step - loss: 7.2091 - mean_squared_error: 7.20910s - loss: 7.2418 - mean_squared_error: 7.24\n",
      "Epoch 117/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.2740 - mean_squared_error: 7.2740\n",
      "Epoch 118/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.2573 - mean_squared_error: 7.2573\n",
      "Epoch 119/200\n",
      "379/379 [==============================] - 0s 971us/step - loss: 7.1580 - mean_squared_error: 7.1580\n",
      "Epoch 120/200\n",
      "379/379 [==============================] - 0s 978us/step - loss: 7.1761 - mean_squared_error: 7.1761\n",
      "Epoch 121/200\n",
      "379/379 [==============================] - 0s 931us/step - loss: 7.2415 - mean_squared_error: 7.2415\n",
      "Epoch 122/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.2175 - mean_squared_error: 7.2175\n",
      "Epoch 123/200\n",
      "379/379 [==============================] - 0s 948us/step - loss: 7.1943 - mean_squared_error: 7.1943\n",
      "Epoch 124/200\n",
      "379/379 [==============================] - 0s 1000us/step - loss: 7.2236 - mean_squared_error: 7.2236\n",
      "Epoch 125/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.2611 - mean_squared_error: 7.2611\n",
      "Epoch 126/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.2107 - mean_squared_error: 7.2107\n",
      "Epoch 127/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1197 - mean_squared_error: 7.1197: 0s - loss: 6.7148 - mean_squared_error\n",
      "Epoch 128/200\n",
      "379/379 [==============================] - 0s 922us/step - loss: 7.2005 - mean_squared_error: 7.2005\n",
      "Epoch 129/200\n",
      "379/379 [==============================] - 0s 921us/step - loss: 7.1974 - mean_squared_error: 7.1974\n",
      "Epoch 130/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.0967 - mean_squared_error: 7.0967\n",
      "Epoch 131/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1067 - mean_squared_error: 7.1067\n",
      "Epoch 132/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1033 - mean_squared_error: 7.1033: 0s - loss: 6.6741 - mean_squared_error: \n",
      "Epoch 133/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1616 - mean_squared_error: 7.1616\n",
      "Epoch 134/200\n",
      "379/379 [==============================] - 0s 941us/step - loss: 7.1537 - mean_squared_error: 7.1537\n",
      "Epoch 135/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1399 - mean_squared_error: 7.1399\n",
      "Epoch 136/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1810 - mean_squared_error: 7.1810\n",
      "Epoch 137/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.0829 - mean_squared_error: 7.0829\n",
      "Epoch 138/200\n",
      "379/379 [==============================] - 0s 969us/step - loss: 6.9924 - mean_squared_error: 6.9924\n",
      "Epoch 139/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1442 - mean_squared_error: 7.1442\n",
      "Epoch 140/200\n",
      "379/379 [==============================] - 0s 974us/step - loss: 7.1891 - mean_squared_error: 7.1891\n",
      "Epoch 141/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.0557 - mean_squared_error: 7.0557\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1094 - mean_squared_error: 7.1094\n",
      "Epoch 143/200\n",
      "379/379 [==============================] - 0s 952us/step - loss: 7.0163 - mean_squared_error: 7.0163\n",
      "Epoch 144/200\n",
      "379/379 [==============================] - 0s 953us/step - loss: 7.1464 - mean_squared_error: 7.1464\n",
      "Epoch 145/200\n",
      "379/379 [==============================] - 0s 896us/step - loss: 7.1557 - mean_squared_error: 7.1557\n",
      "Epoch 146/200\n",
      "379/379 [==============================] - 0s 948us/step - loss: 7.0230 - mean_squared_error: 7.0230\n",
      "Epoch 147/200\n",
      "379/379 [==============================] - 0s 975us/step - loss: 6.9901 - mean_squared_error: 6.9901\n",
      "Epoch 148/200\n",
      "379/379 [==============================] - 0s 957us/step - loss: 7.0334 - mean_squared_error: 7.0334\n",
      "Epoch 149/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.0774 - mean_squared_error: 7.0774\n",
      "Epoch 150/200\n",
      "379/379 [==============================] - 0s 920us/step - loss: 6.9896 - mean_squared_error: 6.9896\n",
      "Epoch 151/200\n",
      "379/379 [==============================] - 0s 925us/step - loss: 7.0726 - mean_squared_error: 7.0726\n",
      "Epoch 152/200\n",
      "379/379 [==============================] - 0s 936us/step - loss: 7.0985 - mean_squared_error: 7.0985\n",
      "Epoch 153/200\n",
      "379/379 [==============================] - 0s 947us/step - loss: 7.0612 - mean_squared_error: 7.06120s - loss: 6.3199 - mean_squared_error: \n",
      "Epoch 154/200\n",
      "379/379 [==============================] - 0s 918us/step - loss: 7.0646 - mean_squared_error: 7.0646\n",
      "Epoch 155/200\n",
      "379/379 [==============================] - 0s 917us/step - loss: 7.0709 - mean_squared_error: 7.0709\n",
      "Epoch 156/200\n",
      "379/379 [==============================] - 0s 926us/step - loss: 6.9435 - mean_squared_error: 6.9435\n",
      "Epoch 157/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 7.1034 - mean_squared_error: 7.1034\n",
      "Epoch 158/200\n",
      "379/379 [==============================] - 0s 947us/step - loss: 7.1004 - mean_squared_error: 7.1004\n",
      "Epoch 159/200\n",
      "379/379 [==============================] - 0s 922us/step - loss: 7.0575 - mean_squared_error: 7.0575\n",
      "Epoch 160/200\n",
      "379/379 [==============================] - 0s 944us/step - loss: 6.9356 - mean_squared_error: 6.9356\n",
      "Epoch 161/200\n",
      "379/379 [==============================] - 0s 929us/step - loss: 7.0522 - mean_squared_error: 7.0522\n",
      "Epoch 162/200\n",
      "379/379 [==============================] - 0s 916us/step - loss: 6.9290 - mean_squared_error: 6.9290\n",
      "Epoch 163/200\n",
      "379/379 [==============================] - 0s 975us/step - loss: 6.9234 - mean_squared_error: 6.9234\n",
      "Epoch 164/200\n",
      "379/379 [==============================] - 0s 916us/step - loss: 7.0589 - mean_squared_error: 7.0589\n",
      "Epoch 165/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.9301 - mean_squared_error: 6.9301\n",
      "Epoch 166/200\n",
      "379/379 [==============================] - 0s 932us/step - loss: 7.0538 - mean_squared_error: 7.0538\n",
      "Epoch 167/200\n",
      "379/379 [==============================] - 0s 919us/step - loss: 6.9068 - mean_squared_error: 6.9068\n",
      "Epoch 168/200\n",
      "379/379 [==============================] - 0s 928us/step - loss: 6.9149 - mean_squared_error: 6.9149\n",
      "Epoch 169/200\n",
      "379/379 [==============================] - 0s 914us/step - loss: 7.0541 - mean_squared_error: 7.0541\n",
      "Epoch 170/200\n",
      "379/379 [==============================] - 0s 896us/step - loss: 7.0129 - mean_squared_error: 7.0129\n",
      "Epoch 171/200\n",
      "379/379 [==============================] - 0s 946us/step - loss: 6.9809 - mean_squared_error: 6.9809\n",
      "Epoch 172/200\n",
      "379/379 [==============================] - 0s 933us/step - loss: 6.9886 - mean_squared_error: 6.9886\n",
      "Epoch 173/200\n",
      "379/379 [==============================] - 0s 910us/step - loss: 6.8712 - mean_squared_error: 6.8712\n",
      "Epoch 174/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.9508 - mean_squared_error: 6.9508\n",
      "Epoch 175/200\n",
      "379/379 [==============================] - 0s 933us/step - loss: 6.9319 - mean_squared_error: 6.93190s - loss: 6.8375 - mean_squared_error: 6.83\n",
      "Epoch 176/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.9731 - mean_squared_error: 6.9731\n",
      "Epoch 177/200\n",
      "379/379 [==============================] - 0s 917us/step - loss: 6.9341 - mean_squared_error: 6.9341\n",
      "Epoch 178/200\n",
      "379/379 [==============================] - 0s 915us/step - loss: 6.9188 - mean_squared_error: 6.9188\n",
      "Epoch 179/200\n",
      "379/379 [==============================] - 0s 926us/step - loss: 6.7983 - mean_squared_error: 6.7983\n",
      "Epoch 180/200\n",
      "379/379 [==============================] - 0s 954us/step - loss: 6.9429 - mean_squared_error: 6.9429\n",
      "Epoch 181/200\n",
      "379/379 [==============================] - 0s 918us/step - loss: 6.9514 - mean_squared_error: 6.9514\n",
      "Epoch 182/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.9266 - mean_squared_error: 6.9266\n",
      "Epoch 183/200\n",
      "379/379 [==============================] - 0s 927us/step - loss: 6.9522 - mean_squared_error: 6.9522\n",
      "Epoch 184/200\n",
      "379/379 [==============================] - 0s 914us/step - loss: 6.9395 - mean_squared_error: 6.9395\n",
      "Epoch 185/200\n",
      "379/379 [==============================] - 0s 927us/step - loss: 6.8338 - mean_squared_error: 6.8338\n",
      "Epoch 186/200\n",
      "379/379 [==============================] - 0s 941us/step - loss: 6.9883 - mean_squared_error: 6.9883\n",
      "Epoch 187/200\n",
      "379/379 [==============================] - 0s 954us/step - loss: 6.8988 - mean_squared_error: 6.8988\n",
      "Epoch 188/200\n",
      "379/379 [==============================] - 0s 924us/step - loss: 6.8174 - mean_squared_error: 6.8174\n",
      "Epoch 189/200\n",
      "379/379 [==============================] - 0s 911us/step - loss: 6.8466 - mean_squared_error: 6.8466\n",
      "Epoch 190/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.8589 - mean_squared_error: 6.8589\n",
      "Epoch 191/200\n",
      "379/379 [==============================] - 0s 926us/step - loss: 6.8490 - mean_squared_error: 6.8490\n",
      "Epoch 192/200\n",
      "379/379 [==============================] - 0s 992us/step - loss: 6.8406 - mean_squared_error: 6.8406\n",
      "Epoch 193/200\n",
      "379/379 [==============================] - 0s 982us/step - loss: 6.7301 - mean_squared_error: 6.7301\n",
      "Epoch 194/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.7829 - mean_squared_error: 6.7829\n",
      "Epoch 195/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.7862 - mean_squared_error: 6.7862\n",
      "Epoch 196/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.8551 - mean_squared_error: 6.8551\n",
      "Epoch 197/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.8352 - mean_squared_error: 6.8352\n",
      "Epoch 198/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.7355 - mean_squared_error: 6.7355\n",
      "Epoch 199/200\n",
      "379/379 [==============================] - 0s 1ms/step - loss: 6.7874 - mean_squared_error: 6.7874\n",
      "Epoch 200/200\n",
      "379/379 [==============================] - 0s 942us/step - loss: 6.7946 - mean_squared_error: 6.7946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cbffb70>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reminder: batch size is a hyperparameter that defines the number of samples to work \n",
    "# through before updating the internal model parameters\n",
    "# For the difference between epochs and batchsize, read: https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "\n",
    "# Using Mini batch GD\n",
    "# Fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size = 1, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8021445497775088"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Regression model\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare our ANN to sklearn's linear regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202131"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_reg = LinearRegression().fit(X_train, y_train)\n",
    "linear_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
